{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKEQRY0ABXQbqEb/Uhx2TS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mnDylan/iris-classification-project/blob/main/Iris_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1 // Install library**"
      ],
      "metadata": {
        "id": "JTHDum4VKoju"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fGZ_OZoKm-f"
      },
      "outputs": [],
      "source": [
        "!pip install firebase-admin"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2 //Import Library**"
      ],
      "metadata": {
        "id": "zSToYTUuLHbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import firebase_admin\n",
        "from firebase_admin import credentials, db, firestore\n",
        "import json\n",
        "from google.colab import files\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "akFi7sGzLMTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3 // Upload file credentials JSON**"
      ],
      "metadata": {
        "id": "Y2GYyFYBLw8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "F82MJ7AqL6l9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = list(uploaded.keys())[0]"
      ],
      "metadata": {
        "id": "Sq67xvcmL6q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4 // Initialize Firebase App**"
      ],
      "metadata": {
        "id": "pKwQU_FiNgnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import firebase_admin\n",
        "from firebase_admin import credentials\n",
        "\n",
        "cred = credentials.Certificate(filename)\n",
        "firebase_admin.initialize_app(cred)\n"
      ],
      "metadata": {
        "id": "C-1SX7KUNkMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5 // Initialize Firestore client**"
      ],
      "metadata": {
        "id": "smIkWkwkNuWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "firestore_db = firestore.client()"
      ],
      "metadata": {
        "id": "gVG0SvdTN1ZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6 // Load Iris Dataset**\n"
      ],
      "metadata": {
        "id": "BZiyg29KQPxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris()\n",
        "iris_df = pd.DataFrame(iris.data, columns = iris.feature_names)\n",
        "iris_df['target'] = iris.target\n",
        "iris_df['target_name'] = iris_df['target'].map(lambda x: iris.target_names[x])\n",
        "\n",
        "print(f\"Dataset shape: {iris_df.shape}\")\n",
        "iris_df.head()\n"
      ],
      "metadata": {
        "id": "eCODeT9wQWbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7 // Insert | Delete Data Into Firebase**"
      ],
      "metadata": {
        "id": "kKY4YklETRr4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## * 7.1 // Insert Data*"
      ],
      "metadata": {
        "id": "_hN3mlTFwzD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_iris_to_firestore():\n",
        "    collection_name = 'iris_dataset'\n",
        "    batch_size = 100\n",
        "    total_records = len(iris_df)\n",
        "\n",
        "    for i in range(0, total_records, batch_size):\n",
        "      batch = firestore_db.batch()\n",
        "      batch_data = iris_df.iloc[i:i+batch_size]\n",
        "      for idx, row in batch_data.iterrows():\n",
        "          doc_ref = firestore_db.collection(collection_name).document(f'sample_{idx}')\n",
        "\n",
        "          # Transfrom numpy type into Python native types\n",
        "          data = {\n",
        "              'sepal_length_cm': float (row['sepal length (cm)']),\n",
        "              'sepal_width_cm': float (row['sepal width (cm)']),\n",
        "              'petal_length_cm': float (row['petal length (cm)']),\n",
        "              'petal_width_cm': float (row['petal width (cm)']),\n",
        "              'target': int (row['target']),\n",
        "              'target_name': str (row['target_name']),\n",
        "              'sample_id': int(idx)\n",
        "          }\n",
        "\n",
        "          batch.set(doc_ref, data)\n",
        "\n",
        "      # Commit batch\n",
        "      batch.commit()\n",
        "      print(f\"Uploaded batch {i//batch_size + 1}: records {i+1}-{min(i+batch_size, total_records)}\")\n",
        "\n",
        "    print(f\"\\nSuccessfully uploaded {total_records} records to Firestore collection '{collection_name}'\")\n",
        "\n",
        "try:\n",
        "  upload_iris_to_firestore()\n",
        "  print('\\n Upload compledted successfully')\n",
        "except Exception as e:\n",
        "  print(f\" Error during upload: {str(e)}\")\n",
        "\n",
        "# Check the uploaded data\n",
        "def verify_upload():\n",
        "    collection_name = 'iris_dataset'\n",
        "    docs = firestore_db.collection(collection_name).limit(5).stream()\n",
        "\n",
        "    print(\"\\nVerifying upload - First 5 documents:\")\n",
        "    for doc in docs:\n",
        "        print(f\"Document ID: {doc.id}\")\n",
        "        print(f\"Data: {doc.to_dict()}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "# RUN CHECK UPLOAD DATA\n",
        "verify_upload()\n",
        "\n",
        "# Uploaded data statistics\n",
        "def get_collection_stats():\n",
        "    collection_name = 'iris_dataset'\n",
        "    docs = list(firestore_db.collection(collection_name).stream())\n",
        "\n",
        "    print(f\"\\nCollection Statistics:\")\n",
        "    print(f\"Total documents: {len(docs)}\")\n",
        "\n",
        "    # Count by target_name\n",
        "    target_counts = {}\n",
        "    for doc in docs:\n",
        "        data = doc.to_dict()\n",
        "        target_name = data.get('target_name', 'unknown')\n",
        "        target_counts[target_name] = target_counts.get(target_name, 0) + 1\n",
        "\n",
        "    print(f\"Distribution by species:\")\n",
        "    for species, count in target_counts.items():\n",
        "        print(f\"  {species}: {count}\")\n",
        "\n",
        "# RUN STATISTICS\n",
        "get_collection_stats()"
      ],
      "metadata": {
        "id": "p0Ba7xSCTZIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## * 7.2 // Delete Data *"
      ],
      "metadata": {
        "id": "1tqWASCxx6iz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_data_firestore():\n",
        "    \"\"\"\n",
        "    Deletes all documents in the 'iris_dataset' Firestore collection.\n",
        "    Use with caution as this operation is irreversible.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Reference to the collection\n",
        "        iris_ref = firestore_db.collection('iris_dataset')\n",
        "\n",
        "        # Get all documents (with batch size limit consideration)\n",
        "        docs = iris_ref.limit(100).stream()  # Firestore has batch operation limits\n",
        "\n",
        "        # Delete each document\n",
        "        deleted_count = 0\n",
        "        for doc in docs:\n",
        "            doc.reference.delete()\n",
        "            deleted_count += 1\n",
        "\n",
        "        print(f\"Successfully deleted {deleted_count} documents.\")\n",
        "        return deleted_count\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error deleting documents: {e}\")\n",
        "        return 0\n"
      ],
      "metadata": {
        "id": "qA2T2pWJ1PYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8 // Load Iris Data From Firestore**"
      ],
      "metadata": {
        "id": "ZApfZKgqsj6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_iris_from_firestore():\n",
        "  iris_ref = firestore_db.collection('iris_dataset')\n",
        "  docs = iris_ref.stream()\n",
        "\n",
        "  records = []\n",
        "  for doc in docs:\n",
        "    data = doc.to_dict()\n",
        "    records.append(data)\n",
        "\n",
        "  # Create Dataframe\n",
        "  iris_df = pd.DataFrame(records)\n",
        "  return iris_df\n",
        "\n",
        "# Load the iris dataset from Firestore\n",
        "load_pd_iris = load_iris_from_firestore()\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "load_pd_iris.head()\n",
        "\n",
        "# Filter rows where target equals 1 (corrected syntax)\n",
        "load_pd_iris[load_pd_iris['target'] == 1]"
      ],
      "metadata": {
        "id": "ox9MxrNhsrLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9 // Visualize Iris Dataset**"
      ],
      "metadata": {
        "id": "VLoP9wQOrsQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_pd_iris.columns"
      ],
      "metadata": {
        "id": "Mj8l-6nZr1Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **10 // Prepare Data for Training**"
      ],
      "metadata": {
        "id": "5nd_HZCu5KkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load Data from Firestore\n",
        "iris_df = load_iris_from_firestore()\n",
        "\n",
        "# Print the columns of the loaded DataFrame to verify\n",
        "print(\"Columns after loading from Firestore:\", iris_df.columns)\n",
        "\n",
        "# Step 2: Prepare Data\n",
        "# X is used for features, y for the target variable\n",
        "X = iris_df[['sepal_length_cm', 'sepal_width_cm','petal_length_cm','petal_width_cm']]\n",
        "y = iris_df['target_name']\n",
        "\n",
        "# Encode target_name (string) to number\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"\\nData prepared and split successfully.\")\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)"
      ],
      "metadata": {
        "id": "t1EyPOIE5OdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **11 // Initialize and Training Decision Tree**"
      ],
      "metadata": {
        "id": "WxyF_rKsB5D7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Model\n",
        "clf = DecisionTreeClassifier(random_state = 42)\n",
        "clf.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "44WIq9yNCFVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prediction\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate Model\n",
        "print(\"\\n Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\n Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names = le.classes_))"
      ],
      "metadata": {
        "id": "u7IBpTmrFNjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vizualize Decision Tree\n",
        "from sklearn.tree import plot_tree\n",
        "\n",
        "plt.figure(figsize =(16, 10))\n",
        "plot_tree(clf, feature_names = X.columns, class_names = le.classes_, filled =True)\n",
        "plt.title(\"Decision Tree for Iris Dataset\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IKujlZaKGKmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **12 // Predict Function**"
      ],
      "metadata": {
        "id": "JWN5d1sdHC6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sample(sepal_length_cm, sepal_width_cm, petal_length_cm, petal_width_cm):\n",
        "  # Create 2D input array for sckit-learn\n",
        "  sample = [[sepal_length_cm, sepal_width_cm, petal_length_cm, petal_width_cm]]\n",
        "\n",
        "  # Predict Label\n",
        "  pred_label = clf.predict(sample)[0]\n",
        "\n",
        "  # Convert Number Label to Species\n",
        "  pred_species = le.inverse_transform([pred_label])[0]\n",
        "\n",
        "  print(\"Prediction:\")\n",
        "  print(f\" Species: {pred_species}\")\n",
        "  return pred_species\n"
      ],
      "metadata": {
        "id": "cnoHKv3vHHGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample test\n",
        "sepal_length_cm = float(input(\"Enter sepal length:\"))\n",
        "sepal_width_cm = float(input(\"Enter sepal width:\"))\n",
        "petal_length_cm = float(input(\"Enter petal length:\"))\n",
        "petal_width_cm = float(input(\"Enter petal width:\"))\n",
        "\n",
        "predict_sample(sepal_length_cm, sepal_width_cm, petal_length_cm, petal_width_cm)"
      ],
      "metadata": {
        "id": "FVPPIQhJIHC6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}